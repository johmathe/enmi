#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass paper
\begin_preamble
\usepackage{tikz}
\newcommand\norm[1]{\left\lVert#1\right\rVert}
\usepackage[hscale=0.7,vscale=0.8]{geometry}
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language french
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize a4paper
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language french
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Néguantropie, opacité et explicabilité des réseaux neuronaux artificiels
 profonds
\end_layout

\begin_layout Author
Johan Mathe johmathe@baylabs.io 
\end_layout

\begin_layout Standard
Remerciements pour etre aussi nombreux et nombreux
\end_layout

\begin_layout Standard
Je tiens a remercier Bernard Stiegler, Raphaele
\end_layout

\begin_layout Standard
Presentations georgescu roden
\end_layout

\begin_layout Standard
Je vous precise simplement que je ne travaille pas exclusivement
\end_layout

\begin_layout Standard
Ce sur quoi je travaille
\end_layout

\begin_layout Standard
20045
\end_layout

\begin_layout Standard
11 ans
\end_layout

\begin_layout Standard
Le geste et la parole/Gesture and Speech, published in 1964, the same year
 in which Kubrick starting work on 2001.
 (Although Leroi-Gourhan’s book was only just translated in 1991, so that
 idea is quite dubious.)
\end_layout

\begin_layout Standard
Dans 2001, K
\end_layout

\begin_layout Standard
TODO: better citations
\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename imgs/sf_symphony_kubrick.jpg
	display false
	width 100col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
SF Symphony et 2001
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Ce travail est né d'une discussion cet été avec Bernard Stiegler autour
 de la computation, de l'IA et des réseaux de neurones.
 Quand j'ai mentionné le fait qu'un de mes axes de recherche et développement
 était l'explicabilité des réseaux de neurones a couches profondes appliquées
 aux problématiques du diagnostique médical, il m'a demandé si une intervention
 au sein du séminaire 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename imgs/2001_speculate.jpg
	display false
	width 100col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Quote from Kubrick
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Baylabs
\end_layout

\begin_layout Standard
Baylabs, Inc est une startup qui a pour mission d'améliorer la qualité,
 valeur et l'acces a l'imagerie médicale.
 Le premier produit sur lequel l'équipe travaille est un systeme d'analyse
 cardiaque basé sur l'utilisation de l'ultrason et de l'echocardiographie.
 Nous travaillons a l'interesection de deux technologies : la miniaturisation
 des techniques d'acquisition de données de scans ultrasons ainsi que le
 l'utilisation des réseaux neuronaux profonds.
 Nous travaillons actuellement en partenariat avec cinq universités et centres
 hospitaliers américains : Stanford University, Northwestern University
 a Chicago, Duke University sur la cote est ainsi que Mineapolis Heart Institute.
 Un de nos premiers prototypes permet de faire du diagnostic des signes
 a vant coureur de la fievre rhumatismale.
 La fièvre rhumatismale est une complication des infections de l’enfance
 et de l’adolescence, qui survient à la suite des angines dues au streptocoque
 hémolytique, et qui n’ont pas été soignées par des antibiotiques.
 Cette pathologie est assez facile a traiter avec des antibiotiques, mais
 difficile a diagnostiquer sans avoir de vision interne du coeur.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename imgs/baylabs_software.jpg
	display false
	width 100col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Quote from Kubrick
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Réseaux neuronaux artificiels profonds
\end_layout

\begin_layout Standard
Je vais maintenant introduire les réseaux de neurones artificiels profonds.
 Cette introduction est largement inspirée d'une parution en anglais 
\begin_inset CommandInset citation
LatexCommand cite
key "Goodfellow-et-al-2016-Book"

\end_inset

.
 Le but d'un réseau neuronal est d'approximer une fonction 
\begin_inset Formula $f^{*}$
\end_inset

.
 Un bon exemple une fonction de classification d'image 
\begin_inset Formula $y=f^{*}(x)$
\end_inset

 qui associe une classe de donnée a une catégorie y.
 Le réseau neuronal définit une application 
\begin_inset Formula $\boldsymbol{y}=f(\boldsymbol{x};\boldsymbol{W})$
\end_inset

 On ne mentionnera pas ici des réseau neuronaux récurrents.
 Ces modeles sont la base d'énormément d'applications.
 La définition de ces modeles est extremement symple.
 En effet il s'agit généralement de la composition de fonctions non-linéaires
 de la forme suivante:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
f(\boldsymbol{x})=f^{(n)}(\ldots f^{(i)}(\ldots f^{(1)}(\boldsymbol{x})))
\]

\end_inset


\end_layout

\begin_layout Standard
Ces structures chainées peuvent etre vues comme un systeme multi couches.
 En effet la fonction 
\begin_inset Formula $f^{(1)}$
\end_inset

 représentera la premiere couche du réseau, jusqu'a 
\begin_inset Formula $f^{(n)}$
\end_inset

la derniere couche 
\begin_inset Formula $n$
\end_inset

 Le nombre de couche est appelé la 
\series bold
profondeur
\series default
 du réseau.
 Un modele graphique representant un reseau a deux couches:
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
def
\backslash
layersep{2.5cm}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
begin{tikzpicture}[shorten >=1pt,->,draw=black!50, node distance=
\backslash
layersep]  
\end_layout

\begin_layout Plain Layout


\backslash
tikzstyle{every pin edge}=[<-,shorten <=1pt]
\end_layout

\begin_layout Plain Layout


\backslash
tikzstyle{neuron}=[circle,fill=black!25,minimum size=17pt,inner sep=0pt]
\end_layout

\begin_layout Plain Layout


\backslash
tikzstyle{input neuron}=[neuron, fill=green!50]    
\end_layout

\begin_layout Plain Layout


\backslash
tikzstyle{output neuron}=[neuron, fill=red!50]    
\end_layout

\begin_layout Plain Layout


\backslash
tikzstyle{hidden neuron}=[neuron, fill=blue!50]    
\end_layout

\begin_layout Plain Layout


\backslash
tikzstyle{annot} = [text width=4em, text centered]
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
foreach 
\backslash
name / 
\backslash
y in {1,...,4}    
\end_layout

\begin_layout Plain Layout

 
\backslash
node[input neuron, pin=left:Entrée 
\backslash
#
\backslash
y] (I-
\backslash
name) at (0,-
\backslash
y) {};
\end_layout

\begin_layout Plain Layout

  
\backslash
foreach 
\backslash
name / 
\backslash
y in {1,...,5}        
\end_layout

\begin_layout Plain Layout

   
\backslash
path[yshift=0.5cm]            
\end_layout

\begin_layout Plain Layout

    node[hidden neuron] (H1-
\backslash
name) at (
\backslash
layersep,-
\backslash
y cm) {};
\end_layout

\begin_layout Plain Layout

  
\end_layout

\begin_layout Plain Layout

  
\backslash
foreach 
\backslash
name / 
\backslash
y in {1,...,5}        
\end_layout

\begin_layout Plain Layout

   
\backslash
path[yshift=0.5cm]            
\end_layout

\begin_layout Plain Layout

    node[hidden neuron] (H2-
\backslash
name) at (5cm,-
\backslash
y cm) {};
\end_layout

\begin_layout Plain Layout

 
\end_layout

\begin_layout Plain Layout

  
\backslash
foreach 
\backslash
source in {1,...,4}         
\end_layout

\begin_layout Plain Layout

   
\backslash
foreach 
\backslash
dest in {1,...,5}  
\end_layout

\begin_layout Plain Layout

    
\backslash
path (I-
\backslash
source) edge (H1-
\backslash
dest);
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

 
\backslash
node[output neuron,pin={[pin edge={->}]right:Sortie}, right of=H2-3] (O)
 {};
\end_layout

\begin_layout Plain Layout

   
\backslash
foreach 
\backslash
source in {1,...,5}         
\end_layout

\begin_layout Plain Layout

    
\backslash
foreach 
\backslash
dest in {1,...,5}  
\end_layout

\begin_layout Plain Layout

     
\backslash
path (H1-
\backslash
source) edge (H2-
\backslash
dest);
\end_layout

\begin_layout Plain Layout

  
\end_layout

\begin_layout Plain Layout

  
\backslash
foreach 
\backslash
source in {1,...,5}      
\end_layout

\begin_layout Plain Layout

   
\backslash
path (H2-
\backslash
source) edge (O);
\end_layout

\begin_layout Plain Layout

 
\backslash
node[annot,above of=H2-1, node distance=1cm] (hl) {Couche cachée~2 $f^{(2)}$};
   
\end_layout

\begin_layout Plain Layout

 
\backslash
node[annot,above of=H1-1, node distance=1cm] (hl) {Couche cachée~1 $f^{(1)}$};
   
\end_layout

\begin_layout Plain Layout

 
\backslash
node[annot,left of=hl] {Couche d'entrée};  
\end_layout

\begin_layout Plain Layout

 
\backslash
node[annot,right of=H2-1] {Couche de sortie}; 
\end_layout

\begin_layout Plain Layout


\backslash
end{tikzpicture}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\boldsymbol{H}=\sigma(\boldsymbol{W}^{T}\boldsymbol{X})
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "48text%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename imgs/rhd_positive.jpg
	display false
	width 100col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Un cas pathologique de fievre rhumatique
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \hfill{}
\end_inset


\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "48text%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename imgs/coeur_sain.png
	display false
	width 100col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Un coeur sain
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
TODO: Example with two pathologies
\end_layout

\begin_layout Subsection
L'apprentissage
\end_layout

\begin_layout Standard
L'apprentissage est un processus souvent itératif qui permet d'estimer une
 fonction de type réseau neuronal grace a une grande quantité de données
 d'entrée.
 Dans notre cas de classification d'images pathologiques ou non, nous aurons
 un ensemble de tuples 
\begin_inset Formula $(X_{i},y_{i})$
\end_inset

 qui correspondront tout simplement aux images et a leurs labels, c'est
 a dire s'il s'agit d'un cas pathologique ou non.
\end_layout

\begin_layout Standard
D'un point de vue mathématique on peut voir le probleme de l'apprentissage
 comme un probleme d'optimisation.
 Il s'agit de minimiser la somme des erreur entre les prédictions de notre
 réseau de neurones et les données labellisées par des experts (dans notre
 cas les experts du monde médical).
 Nous nous retrouvons donc avec la forme suivante:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
\mbox{\mbox{minimiser}} & J(\boldsymbol{\theta,y,X})=\sum_{i=1}^{N}\lVert y_{i}-f(X_{i};\boldsymbol{\theta}))\rVert^{2}
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
La minimisation de cette valeur se fait par l'algorithme du gradient (aussi
 appelé gradient descent, steepest descent).
 L'idée relativement simple.
 On commence par choisir un point aléatoire 
\begin_inset Formula $\boldsymbol{\theta}_{0}$
\end_inset

, puis on évalue la valeur du gradient 
\begin_inset Formula $\nabla_{\theta}J(\boldsymbol{\theta})$
\end_inset

 en ce point.
 Ce gradient représente un hyperplan dans l'espace a 
\begin_inset Formula $m$
\end_inset

 dimensions des parametres de notre fonction 
\begin_inset Formula $f(x;\boldsymbol{\theta})$
\end_inset

.
 On fait ensuite une mise a jour de notre parametre qui devient 
\begin_inset Formula $\boldsymbol{\theta}_{1}$
\end_inset

 en lui ajoutant une partie de ce gradient, pondéré par un taux d'apprentissage
 
\begin_inset Formula $\alpha$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\boldsymbol{\theta}[k+1]=\boldsymbol{\theta}[k]+\alpha\nabla_{\boldsymbol{\theta}}J(\boldsymbol{\theta,y,X})
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename imgs/gradient_descent.pdf
	display false
	width 100col%
	height 100col%

\end_inset


\end_layout

\begin_layout Subsection
Convexité
\end_layout

\begin_layout Standard
Il est important de mentionner 
\end_layout

\begin_layout Standard
La définition d'un ensemble convexe est la suivante:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\forall x,y\in C\quad\forall t\in[0,1]\qquad tx+(1-t)y\in C
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
La définition d'une fonction convexe est la suivante
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
f\left(tx+(1-t)y\right)\leq t\,f(x)+(1-t)\,f(y)
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename imgs/non_convex.pdf
	display false
	width 100text%

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename imgs/convex.pdf
	display false
	width 100text%

\end_inset

 
\end_layout

\begin_layout Subsection
Entropie Croisée
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
H_{y'}(y)=\sum_{i}y_{i}'\log(y_{i})
\end{equation}

\end_inset


\end_layout

\begin_layout Subsection
Optimisation
\end_layout

\begin_layout Standard
On veut quantifier l'information d'une maniere qui formalise une forme d'intuiti
on.
 
\end_layout

\begin_layout Itemize
Les evenements qui sont fortement probable devraient avoir un contenu en
 information faible, et les evements qui sont garantis devraient avoir un
 contenu informationel proche de zéro.
 Un exemple typique est que le soleil se leverea demain.
 Cette phrase a un contenu informationel faible si l'on connait l'histoire
 des levers et couchers de soleils depuis le début de l'histoire de l'humanité.
\end_layout

\begin_layout Itemize
Les evenements peu probables devraient avoir un contenu informationel élevé.
 Les évemenents independants devraient avoir une information additive.
 Par exemple.
 se rendre compte que lors d'un lancer de dés est tombé sur pile deux fois
\end_layout

\begin_layout Standard
Shannon a théorisé dans son papier 
\series bold
A Mathematical Theory of Communication 
\series default
l'entropie comme suit: 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
I(x)=-\log P(x)
\]

\end_inset


\end_layout

\begin_layout Standard
Entropy de gibbs, entropy de von neumann
\end_layout

\begin_layout Standard
Self-information deals only with a single outcome.
 We can quantify the amountof uncertainty in an entire probability distribution
 using the Shannon entropy:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
H(x)\mathbb{=E}_{x\sim P}[I(x)]=-\mathbb{E}_{X\sim P}[\log(x)]
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\sigma(x)=\max(0,x)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename imgs/non_linear.pdf
	display false
	width 100col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Inspection/Destruction de HAL9000
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Je ne vais pas vous parler de propagation arriere car je ne considere pas
 que ceci soit central et necessaire a la comprehension des reseaux neuronaux.
\end_layout

\begin_layout Standard
Bio-inspirés, mon cul.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
w[k]=w[k]-\eta\nabla Q(w[k])=w[k]-\eta\sum_{i=1}^{n}\nabla Q_{i}(w[k])
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
C=-\frac{1}{n}\sum_{x}[y\ln a+(1-y)\ln(1-a)]
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
-\log P[data|model]=\frac{1}{N}
\]

\end_inset


\end_layout

\begin_layout Standard
soft max
\end_layout

\begin_layout Standard
soft arg max
\end_layout

\begin_layout Standard
not talking about 
\end_layout

\begin_layout Section
Opacité, Explicabilité
\end_layout

\begin_layout Subsection
Opacité
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename imgs/mind_going.png
	display false
	width 100col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Inspection/Destruction de HAL9000
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
Une des plus grandes problématiques posées aujourd'hui par les réseaux de
 neurones profonds est liée a ce qu'on peut définir comme l'opacité et le
 manque d'explicabilitié de ceux-cis.
\end_layout

\begin_layout Standard
Transhumanisme
\end_layout

\begin_layout Standard
exosommatisation
\end_layout

\begin_layout Standard
Opacité
\end_layout

\begin_layout Standard
Pour diminuer l'opacité de ce type d'algorithmes, nous nous penchons sur
 une technique relativement ancienne, mais qui a été re popularisée récemment
 grace aux travaux de Erhan et al 2009 TODO Citations.
 Il s'agit simplement de l'operation inverse de l'apprentissage.
 Nous avons vu que l'apprentissage consistait simplement en une optimisation
 d'une fonction d'objectif visant a minimiser une erreur de prédiction,
 ou encore une entropie croisée entre une distribution attendue et une distribut
ion produite par le réseau de neurones.
\end_layout

\begin_layout Standard
Ici nous allons maximiser une activation en considerant la fonction inverse
 de notre reseau de neurones:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
h^{*}(\boldsymbol{X},\boldsymbol{\theta})=f^{*-1}(\boldsymbol{X},\boldsymbol{\theta})
\]

\end_inset


\end_layout

\begin_layout Standard
Nous solvons donc le probleme d'optimisation suivant:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\boldsymbol{X^{*}}=\mbox{argmax}h(\boldsymbol{\theta},\boldsymbol{X})
\]

\end_inset


\end_layout

\begin_layout Standard
TODO review this
\end_layout

\begin_layout Standard
Nous pouvons reutiliser la méthode de l'algorithme du gradient
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand cite
key "Goodfellow-et-al-2016-Book"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand cite
key "visualization_techreport"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand cite
key "yosinski-2015-ICML-DL-understanding-neural-networks"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "45text%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename imgs/rhd_positive.jpg
	display false
	width 100col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Un cas pathologique de fievre rhumatique
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \hfill{}
\end_inset


\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "45text%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename imgs/opacite1.jpg
	display false
	width 100col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Analyse de l'opacité, exemple 1
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "45text%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename imgs/opacite2.jpg
	display false
	width 100col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Analyse de l'opacité, exemple 2
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Explicabilité
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename imgs/heatmap.png
	display false
	width 100col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Inspection/Destruction de HAL9000
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Néguantropie
\end_layout

\begin_layout Standard
Approche pharmacologique en vue d'eviter le besoin de ce truc la
\end_layout

\begin_layout Standard
Theorisation de la singularité
\end_layout

\begin_layout Standard
the ideal superior man of the future who could rise above conventional Christian
 morality to create and impose his own values, originally described by Nietzsche
 in Thus Spake Zarathustra (1883–85).
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename imgs/ubermensch.png
	display false
	width 100col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
proposition : ubermesch selon kubrick
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename imgs/singularity.png
	display false
	width 100col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
proposition : Singularité selon Kubrick
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Softmax
\end_layout

\begin_layout Standard
Le craft revient a la contribution
\end_layout

\begin_layout Standard
mentors
\end_layout

\begin_layout Standard
immitation d'un modele scientifique pour faire science
\end_layout

\begin_layout Standard
exosommatisation pousse 
\end_layout

\begin_layout Standard
remerciements
\end_layout

\begin_layout Standard
pas d'accord avec les energies solaires
\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "dl"
options "plain"

\end_inset


\end_layout

\end_body
\end_document
