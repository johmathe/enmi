#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\begin_preamble
\usepackage{tikz}
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language french
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language french
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Néguantropie, opacité et explicabilité des réseaux neuronaux artificiels
 profonds
\end_layout

\begin_layout Author
Johan Mathe johmathe@baylabs.io 
\end_layout

\begin_layout Standard
Remerciements pour etre aussi nombreux et nombreux
\end_layout

\begin_layout Standard
Je tiens a remercier Bernard Stiegler, Raphaele
\end_layout

\begin_layout Standard
Presentations georgescu roden
\end_layout

\begin_layout Standard
Je vous precise simplement que je ne travaille pas exclusivement
\end_layout

\begin_layout Standard
Ce sur quoi je travaille
\end_layout

\begin_layout Standard
20045
\end_layout

\begin_layout Standard
11 ans
\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
Dans son film 2001, a space odyssey, kubrick nous fait voyager
\end_layout

\begin_layout Section
Réseaux neuronaux artificiels profonds
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
def
\backslash
layersep{2.5cm}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
begin{tikzpicture}[shorten >=1pt,->,draw=black!50, node distance=
\backslash
layersep]  
\end_layout

\begin_layout Plain Layout


\backslash
tikzstyle{every pin edge}=[<-,shorten <=1pt]
\end_layout

\begin_layout Plain Layout


\backslash
tikzstyle{neuron}=[circle,fill=black!25,minimum size=17pt,inner sep=0pt]
\end_layout

\begin_layout Plain Layout


\backslash
tikzstyle{input neuron}=[neuron, fill=green!50]    
\end_layout

\begin_layout Plain Layout


\backslash
tikzstyle{output neuron}=[neuron, fill=red!50]    
\end_layout

\begin_layout Plain Layout


\backslash
tikzstyle{hidden neuron}=[neuron, fill=blue!50]    
\end_layout

\begin_layout Plain Layout


\backslash
tikzstyle{annot} = [text width=4em, text centered]
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
foreach 
\backslash
name / 
\backslash
y in {1,...,4}    
\end_layout

\begin_layout Plain Layout

 
\backslash
node[input neuron, pin=left:Entrée 
\backslash
#
\backslash
y] (I-
\backslash
name) at (0,-
\backslash
y) {};
\end_layout

\begin_layout Plain Layout

  
\backslash
foreach 
\backslash
name / 
\backslash
y in {1,...,5}        
\end_layout

\begin_layout Plain Layout

   
\backslash
path[yshift=0.5cm]            
\end_layout

\begin_layout Plain Layout

    node[hidden neuron] (H1-
\backslash
name) at (
\backslash
layersep,-
\backslash
y cm) {};
\end_layout

\begin_layout Plain Layout

  
\end_layout

\begin_layout Plain Layout

  
\backslash
foreach 
\backslash
name / 
\backslash
y in {1,...,5}        
\end_layout

\begin_layout Plain Layout

   
\backslash
path[yshift=0.5cm]            
\end_layout

\begin_layout Plain Layout

    node[hidden neuron] (H2-
\backslash
name) at (5cm,-
\backslash
y cm) {};
\end_layout

\begin_layout Plain Layout

 
\end_layout

\begin_layout Plain Layout

  
\backslash
foreach 
\backslash
source in {1,...,4}         
\end_layout

\begin_layout Plain Layout

   
\backslash
foreach 
\backslash
dest in {1,...,5}  
\end_layout

\begin_layout Plain Layout

    
\backslash
path (I-
\backslash
source) edge (H1-
\backslash
dest);
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

 
\backslash
node[output neuron,pin={[pin edge={->}]right:Sortie}, right of=H2-3] (O)
 {};
\end_layout

\begin_layout Plain Layout

   
\backslash
foreach 
\backslash
source in {1,...,5}         
\end_layout

\begin_layout Plain Layout

    
\backslash
foreach 
\backslash
dest in {1,...,5}  
\end_layout

\begin_layout Plain Layout

     
\backslash
path (H1-
\backslash
source) edge (H2-
\backslash
dest);
\end_layout

\begin_layout Plain Layout

  
\end_layout

\begin_layout Plain Layout

  
\backslash
foreach 
\backslash
source in {1,...,5}      
\end_layout

\begin_layout Plain Layout

   
\backslash
path (H2-
\backslash
source) edge (O);
\end_layout

\begin_layout Plain Layout

 
\backslash
node[annot,above of=H2-1, node distance=1cm] (hl) {Couche cachée N};   
\end_layout

\begin_layout Plain Layout

 
\backslash
node[annot,above of=H1-1, node distance=1cm] (hl) {Couche cachée 1};   
\end_layout

\begin_layout Plain Layout

 
\backslash
node[annot,left of=hl] {Couche d'entrée};  
\end_layout

\begin_layout Plain Layout

 
\backslash
node[annot,right of=H2-1] {Couche de sortie}; 
\end_layout

\begin_layout Plain Layout


\backslash
end{tikzpicture}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\boldsymbol{H}=\sigma(\boldsymbol{W}^{T}\boldsymbol{X})
\end{equation}

\end_inset


\end_layout

\begin_layout Subsection
Entropie Croisée
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
H_{y'}(y)=\sum_{i}y_{i}'\log(y_{i})
\end{equation}

\end_inset


\end_layout

\begin_layout Subsection
Optimisation
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray}
\mbox{minimize} & f_{0}(x)\\
\mbox{subject to} & f_{i}(x)\le b_{i}
\end{eqnarray}

\end_inset


\end_layout

\begin_layout Standard
e would like to quantify information in a way that formalizes this intuition.Spec
iﬁcally,•Likely events should have low information content, and in the extreme
 case,events that are guaranteed to happen should have no information contentwha
tsoever.• Less likely events should have higher information content.•Independent
 events should have additive information.
 For example, ﬁndingout that a tossed coin has come up as heads twice should
 convey twice asmuch information as ﬁnding out that a tossed coin has come
 up as headsonce
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
I(x)=-\log P(x)
\]

\end_inset


\end_layout

\begin_layout Standard
Self-information deals only with a single outcome.
 We can quantify the amountof uncertainty in an entire probability distribution
 using the Shannon entropy:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
H(x)\mathbb{E}()
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $ $
\end_inset


\end_layout

\begin_layout Subsection
Convexité
\end_layout

\begin_layout Standard
La définition d'un ensemble convexe est la suivante:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\forall x,y\in C\quad\forall t\in[0,1]\qquad tx+(1-t)y\in C
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
La définition d'une fonction convexe est la suivante
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
f\left(tx+(1-t)y\right)\leq t\,f(x)+(1-t)\,f(y)
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename imgs/non_convex.pdf
	display false
	width 100text%

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename imgs/convex.pdf
	display false
	width 100text%

\end_inset

 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
w[k]=w[k]-\eta\nabla Q(w[k])=w[k]-\eta\sum_{i=1}^{n}\nabla Q_{i}(w[k])
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
C=-\frac{1}{n}\sum_{x}[y\ln a+(1-y)\ln(1-a)]
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
-\log P[data|model]=\frac{1}{N}
\]

\end_inset


\end_layout

\begin_layout Standard
soft max
\end_layout

\begin_layout Standard
soft arg max
\end_layout

\begin_layout Standard
not talking about 
\end_layout

\begin_layout Section
Opacité, Explicabilité
\end_layout

\begin_layout Standard
Transhumanisme
\end_layout

\begin_layout Standard
exosommatisation
\end_layout

\begin_layout Section
CraftPunk
\end_layout

\begin_layout Standard
Softmax
\end_layout

\begin_layout Standard
Le craft revient a la contribution
\end_layout

\begin_layout Standard
mentors
\end_layout

\begin_layout Standard
immitation d'un modele scientifique pour faire science
\end_layout

\begin_layout Standard
exosommatisation pousse 
\end_layout

\begin_layout Standard
remerciements
\end_layout

\begin_layout Standard
pas d'accord avec les energies solaires
\end_layout

\end_body
\end_document
